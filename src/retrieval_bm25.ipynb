{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alaaeddinalia/Desktop/thesis_submission /Rumor_verification/venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 : 0.6044\n",
      "Recall@10: 0.7029\n",
      "Recall@15: 0.7436\n",
      "Mean Average Precision (MAP): 0.6226\n"
     ]
    }
   ],
   "source": [
    "from preparing.data_loading import DataLoader\n",
    "from preparing.preprocessor import Preprocessor\n",
    "from preparing.data_cleaning import DataCleaner\n",
    "from utils.preprocessing import preprocess_data\n",
    "from utils.feature_extractor import FeatureExtractor\n",
    "from evaluation.retrieval_evaluation_bm25 import evaluate_recall_at_k_bm25, evaluate_map_bm25\n",
    "from utils.data_split import load_and_combine_datasets, stratified_split\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "train_file = '/Users/alaaeddinalia/Desktop/thesis_submission /Rumor_verification/data/raw/English_train.json'\n",
    "dev_file = '/Users/alaaeddinalia/Desktop/thesis_submission /Rumor_verification/data/raw/English_dev.json'\n",
    "\n",
    "# Combine datasets \n",
    "data = load_and_combine_datasets(train_file, dev_file)\n",
    "\n",
    "# Clean data\n",
    "cleaner = DataCleaner()\n",
    "clean_data = cleaner.remove_invalid_tweets(data)\n",
    "\n",
    "# Preprocess dataset\n",
    "preprocessor = Preprocessor()\n",
    "preprocessed_data = preprocess_data(clean_data, preprocessor)\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = stratified_split(preprocessed_data, label_key='label')\n",
    "\n",
    "# Initialize the BM25 \n",
    "extractor = FeatureExtractor(method=\"bm25\")\n",
    "\n",
    "\n",
    "for item in test_data:\n",
    "    rumor_text = item['rumor']  \n",
    "    timeline_texts = [timeline_entry[2] for timeline_entry in item['timeline']] \n",
    "    \n",
    "    # Fit the BM25 model\n",
    "    extractor.fit_transform(timeline_texts)  \n",
    "    \n",
    "    # Calculate BM25 scores \n",
    "    bm25_scores = extractor._bm25_transform([rumor_text])\n",
    "    \n",
    "    # Assign BM25 scores to the corresponding timeline entries\n",
    "    for i, timeline_entry in enumerate(item['timeline']):\n",
    "        timeline_entry.append(bm25_scores[0][i]) \n",
    "\n",
    "\n",
    "# Recall at k\n",
    "recall_at_5 = evaluate_recall_at_k_bm25(test_data,5)\n",
    "recall_at_10 = evaluate_recall_at_k_bm25(test_data,10)\n",
    "recall_at_15 = evaluate_recall_at_k_bm25(test_data,15)\n",
    "\n",
    "# MAP\n",
    "map_score = evaluate_map_bm25(test_data)\n",
    "\n",
    "\n",
    "print(f\"Recall@5 : {recall_at_5:.4f}\")\n",
    "print(f\"Recall@10: {recall_at_10:.4f}\")\n",
    "print(f\"Recall@15: {recall_at_15:.4f}\")\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 : 0.7833\n",
      "Recall@10: 0.8222\n",
      "Recall@15: 0.9000\n",
      "Mean Average Precision (MAP): 0.7937\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the data\n",
    "train_file = '/Users/alaaeddinalia/Desktop/thesis_submission /Rumor_verification/data/raw/Arabic_train.json'\n",
    "dev_file = '/Users/alaaeddinalia/Desktop/thesis_submission /Rumor_verification/data/raw/Arabic_dev.json'\n",
    "\n",
    "# Combine datasets \n",
    "data = load_and_combine_datasets(train_file, dev_file)\n",
    "\n",
    "# Clean data\n",
    "cleaner = DataCleaner()\n",
    "clean_data = cleaner.remove_invalid_tweets(data)\n",
    "\n",
    "# Preprocess dataset\n",
    "preprocessor = Preprocessor()\n",
    "preprocessed_data = preprocess_data(clean_data, preprocessor)\n",
    "\n",
    "# Split the data \n",
    "train_data, test_data = stratified_split(preprocessed_data, label_key='label')\n",
    "\n",
    "# Initialize the BM25 \n",
    "extractor = FeatureExtractor(method=\"bm25\")\n",
    "\n",
    "\n",
    "for item in test_data:\n",
    "    rumor_text = item['rumor']  \n",
    "    timeline_texts = [timeline_entry[2] for timeline_entry in item['timeline']] \n",
    "    \n",
    "    # Fit the BM25 model \n",
    "    extractor.fit_transform(timeline_texts)  \n",
    "    \n",
    "    # Calculate BM25 scores \n",
    "    bm25_scores = extractor._bm25_transform([rumor_text])\n",
    "    \n",
    "    # Assign BM25 scores to the corresponding timeline entries\n",
    "    for i, timeline_entry in enumerate(item['timeline']):\n",
    "        timeline_entry.append(bm25_scores[0][i]) \n",
    "\n",
    "\n",
    "# Recall at k\n",
    "recall_at_5 = evaluate_recall_at_k_bm25(test_data,5)\n",
    "recall_at_10 = evaluate_recall_at_k_bm25(test_data,10)\n",
    "recall_at_15 = evaluate_recall_at_k_bm25(test_data,15)\n",
    "\n",
    "# MAP\n",
    "map_score = evaluate_map_bm25(test_data)\n",
    "\n",
    "\n",
    "print(f\"Recall@5 : {recall_at_5:.4f}\")\n",
    "print(f\"Recall@10: {recall_at_10:.4f}\")\n",
    "print(f\"Recall@15: {recall_at_15:.4f}\")\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "104b1e582622f16709a9992a99be4bbc9dea93f31728655411d1793dc31798ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
